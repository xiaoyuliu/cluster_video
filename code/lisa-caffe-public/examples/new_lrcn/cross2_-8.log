I1123 11:45:00.837098 14481 caffe.cpp:136] Use GPU with device ID 0
I1123 11:45:01.172912 14481 caffe.cpp:144] Starting Optimization
I1123 11:45:01.173046 14481 solver.cpp:45] Initializing solver from parameters: 
test_iter: 81
test_interval: 7777
base_lr: 1e-08
display: 20
max_iter: 4055
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
stepsize: 1622
snapshot: 811
snapshot_prefix: "/local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8"
solver_mode: GPU
device_id: 0
random_seed: 1701
net: "train_test_singleFrame_RGB.prototxt"
test_state {
  stage: "test-on-test"
}
test_initialization: false
I1123 11:45:01.173089 14481 solver.cpp:83] Creating training net from net file: train_test_singleFrame_RGB.prototxt
I1123 11:45:01.173560 14481 net.cpp:258] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1123 11:45:01.173569 14481 net.cpp:258] The NetState phase (0) differed from the phase (1) specified by a rule in layer test_label
I1123 11:45:01.173586 14481 net.cpp:258] The NetState phase (0) differed from the phase (1) specified by a rule in layer loss
I1123 11:45:01.173800 14481 net.cpp:42] Initializing net from parameters: 
name: "singleFrame_RGB"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 103.939
    mean_value: 116.779
    mean_value: 123.68
    flow: false
  }
  image_data_param {
    source: "/local-scratch/xla193/cluster_video_/output/UCF-101/list_frm-labelvect-fix-veri-1ft-random.txt"
    batch_size: 50
    shuffle: false
    new_height: 240
    new_width: 320
    root_folder: "frames/"
  }
}
layer {
  name: "train_label"
  type: "HDF5Data"
  top: "train_label"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/local-scratch/xla193/cluster_video_/output/UCF-101/train_label_fix_1.txt"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 5
    group: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "Python"
  bottom: "fc7"
  bottom: "train_label"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  include {
    phase: TRAIN
  }
  python_param {
    module: "mylayers"
    layer: "HardTripletLossLayer"
  }
}
I1123 11:45:01.173923 14481 layer_factory.hpp:74] Creating layer data
I1123 11:45:01.173940 14481 net.cpp:84] Creating Layer data
I1123 11:45:01.173948 14481 net.cpp:339] data -> data
I1123 11:45:01.173972 14481 net.cpp:339] data -> label
I1123 11:45:01.173982 14481 net.cpp:113] Setting up data
I1123 11:45:01.173990 14481 image_data_layer.cpp:41] Opening file /local-scratch/xla193/cluster_video_/output/UCF-101/list_frm-labelvect-fix-veri-1ft-random.txt
I1123 11:45:01.187625 14481 image_data_layer.cpp:56] A total of 40535 images.
I1123 11:45:01.188650 14481 image_data_layer.cpp:86] output data size: 50,3,227,227
I1123 11:45:01.192309 14481 net.cpp:120] Top shape: 50 3 227 227 (7729350)
I1123 11:45:01.192318 14481 net.cpp:120] Top shape: 50 (50)
I1123 11:45:01.192327 14481 layer_factory.hpp:74] Creating layer train_label
I1123 11:45:01.192338 14481 net.cpp:84] Creating Layer train_label
I1123 11:45:01.192344 14481 net.cpp:339] train_label -> train_label
I1123 11:45:01.192366 14481 net.cpp:113] Setting up train_label
I1123 11:45:01.192373 14481 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /local-scratch/xla193/cluster_video_/output/UCF-101/train_label_fix_1.txt
I1123 11:45:01.192401 14481 hdf5_data_layer.cpp:94] Number of HDF5 files: 1
I1123 11:45:01.195807 14481 net.cpp:120] Top shape: 50 10 (500)
I1123 11:45:01.195821 14481 layer_factory.hpp:74] Creating layer conv1
I1123 11:45:01.195837 14481 net.cpp:84] Creating Layer conv1
I1123 11:45:01.195844 14481 net.cpp:381] conv1 <- data
I1123 11:45:01.195859 14481 net.cpp:339] conv1 -> conv1
I1123 11:45:01.195873 14481 net.cpp:113] Setting up conv1
I1123 11:45:01.196049 14481 net.cpp:120] Top shape: 50 96 111 111 (59140800)
I1123 11:45:01.196060 14481 layer_factory.hpp:74] Creating layer relu1
I1123 11:45:01.196066 14481 net.cpp:84] Creating Layer relu1
I1123 11:45:01.196070 14481 net.cpp:381] relu1 <- conv1
I1123 11:45:01.196074 14481 net.cpp:328] relu1 -> conv1 (in-place)
I1123 11:45:01.196079 14481 net.cpp:113] Setting up relu1
I1123 11:45:01.196085 14481 net.cpp:120] Top shape: 50 96 111 111 (59140800)
I1123 11:45:01.196089 14481 layer_factory.hpp:74] Creating layer pool1
I1123 11:45:01.196094 14481 net.cpp:84] Creating Layer pool1
I1123 11:45:01.196096 14481 net.cpp:381] pool1 <- conv1
I1123 11:45:01.196101 14481 net.cpp:339] pool1 -> pool1
I1123 11:45:01.196107 14481 net.cpp:113] Setting up pool1
I1123 11:45:01.196120 14481 net.cpp:120] Top shape: 50 96 55 55 (14520000)
I1123 11:45:01.196122 14481 layer_factory.hpp:74] Creating layer norm1
I1123 11:45:01.196128 14481 net.cpp:84] Creating Layer norm1
I1123 11:45:01.196132 14481 net.cpp:381] norm1 <- pool1
I1123 11:45:01.196136 14481 net.cpp:339] norm1 -> norm1
I1123 11:45:01.196143 14481 net.cpp:113] Setting up norm1
I1123 11:45:01.196151 14481 net.cpp:120] Top shape: 50 96 55 55 (14520000)
I1123 11:45:01.196153 14481 layer_factory.hpp:74] Creating layer conv2
I1123 11:45:01.196158 14481 net.cpp:84] Creating Layer conv2
I1123 11:45:01.196162 14481 net.cpp:381] conv2 <- norm1
I1123 11:45:01.196166 14481 net.cpp:339] conv2 -> conv2
I1123 11:45:01.196171 14481 net.cpp:113] Setting up conv2
I1123 11:45:01.200381 14481 net.cpp:120] Top shape: 50 384 26 26 (12979200)
I1123 11:45:01.200390 14481 layer_factory.hpp:74] Creating layer relu2
I1123 11:45:01.200397 14481 net.cpp:84] Creating Layer relu2
I1123 11:45:01.200399 14481 net.cpp:381] relu2 <- conv2
I1123 11:45:01.200403 14481 net.cpp:328] relu2 -> conv2 (in-place)
I1123 11:45:01.200408 14481 net.cpp:113] Setting up relu2
I1123 11:45:01.200412 14481 net.cpp:120] Top shape: 50 384 26 26 (12979200)
I1123 11:45:01.200415 14481 layer_factory.hpp:74] Creating layer pool2
I1123 11:45:01.200420 14481 net.cpp:84] Creating Layer pool2
I1123 11:45:01.200424 14481 net.cpp:381] pool2 <- conv2
I1123 11:45:01.200429 14481 net.cpp:339] pool2 -> pool2
I1123 11:45:01.200434 14481 net.cpp:113] Setting up pool2
I1123 11:45:01.200440 14481 net.cpp:120] Top shape: 50 384 13 13 (3244800)
I1123 11:45:01.200444 14481 layer_factory.hpp:74] Creating layer norm2
I1123 11:45:01.200448 14481 net.cpp:84] Creating Layer norm2
I1123 11:45:01.200451 14481 net.cpp:381] norm2 <- pool2
I1123 11:45:01.200455 14481 net.cpp:339] norm2 -> norm2
I1123 11:45:01.200460 14481 net.cpp:113] Setting up norm2
I1123 11:45:01.200466 14481 net.cpp:120] Top shape: 50 384 13 13 (3244800)
I1123 11:45:01.200469 14481 layer_factory.hpp:74] Creating layer conv3
I1123 11:45:01.200474 14481 net.cpp:84] Creating Layer conv3
I1123 11:45:01.200477 14481 net.cpp:381] conv3 <- norm2
I1123 11:45:01.200482 14481 net.cpp:339] conv3 -> conv3
I1123 11:45:01.200486 14481 net.cpp:113] Setting up conv3
I1123 11:45:01.215425 14481 net.cpp:120] Top shape: 50 512 13 13 (4326400)
I1123 11:45:01.215442 14481 layer_factory.hpp:74] Creating layer relu3
I1123 11:45:01.215451 14481 net.cpp:84] Creating Layer relu3
I1123 11:45:01.215456 14481 net.cpp:381] relu3 <- conv3
I1123 11:45:01.215461 14481 net.cpp:328] relu3 -> conv3 (in-place)
I1123 11:45:01.215466 14481 net.cpp:113] Setting up relu3
I1123 11:45:01.215471 14481 net.cpp:120] Top shape: 50 512 13 13 (4326400)
I1123 11:45:01.215474 14481 layer_factory.hpp:74] Creating layer conv4
I1123 11:45:01.215481 14481 net.cpp:84] Creating Layer conv4
I1123 11:45:01.215484 14481 net.cpp:381] conv4 <- conv3
I1123 11:45:01.215489 14481 net.cpp:339] conv4 -> conv4
I1123 11:45:01.215495 14481 net.cpp:113] Setting up conv4
I1123 11:45:01.225165 14481 net.cpp:120] Top shape: 50 512 13 13 (4326400)
I1123 11:45:01.225178 14481 layer_factory.hpp:74] Creating layer relu4
I1123 11:45:01.225186 14481 net.cpp:84] Creating Layer relu4
I1123 11:45:01.225189 14481 net.cpp:381] relu4 <- conv4
I1123 11:45:01.225194 14481 net.cpp:328] relu4 -> conv4 (in-place)
I1123 11:45:01.225200 14481 net.cpp:113] Setting up relu4
I1123 11:45:01.225204 14481 net.cpp:120] Top shape: 50 512 13 13 (4326400)
I1123 11:45:01.225208 14481 layer_factory.hpp:74] Creating layer conv5
I1123 11:45:01.225214 14481 net.cpp:84] Creating Layer conv5
I1123 11:45:01.225216 14481 net.cpp:381] conv5 <- conv4
I1123 11:45:01.225220 14481 net.cpp:339] conv5 -> conv5
I1123 11:45:01.225225 14481 net.cpp:113] Setting up conv5
I1123 11:45:01.233067 14481 net.cpp:120] Top shape: 50 384 13 13 (3244800)
I1123 11:45:01.233081 14481 layer_factory.hpp:74] Creating layer relu5
I1123 11:45:01.233088 14481 net.cpp:84] Creating Layer relu5
I1123 11:45:01.233093 14481 net.cpp:381] relu5 <- conv5
I1123 11:45:01.233096 14481 net.cpp:328] relu5 -> conv5 (in-place)
I1123 11:45:01.233103 14481 net.cpp:113] Setting up relu5
I1123 11:45:01.233108 14481 net.cpp:120] Top shape: 50 384 13 13 (3244800)
I1123 11:45:01.233110 14481 layer_factory.hpp:74] Creating layer pool5
I1123 11:45:01.233117 14481 net.cpp:84] Creating Layer pool5
I1123 11:45:01.233120 14481 net.cpp:381] pool5 <- conv5
I1123 11:45:01.233125 14481 net.cpp:339] pool5 -> pool5
I1123 11:45:01.233131 14481 net.cpp:113] Setting up pool5
I1123 11:45:01.233139 14481 net.cpp:120] Top shape: 50 384 6 6 (691200)
I1123 11:45:01.233142 14481 layer_factory.hpp:74] Creating layer fc6
I1123 11:45:01.233149 14481 net.cpp:84] Creating Layer fc6
I1123 11:45:01.233151 14481 net.cpp:381] fc6 <- pool5
I1123 11:45:01.233156 14481 net.cpp:339] fc6 -> fc6
I1123 11:45:01.233165 14481 net.cpp:113] Setting up fc6
I1123 11:45:01.673215 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:01.673233 14481 layer_factory.hpp:74] Creating layer relu6
I1123 11:45:01.673240 14481 net.cpp:84] Creating Layer relu6
I1123 11:45:01.673244 14481 net.cpp:381] relu6 <- fc6
I1123 11:45:01.673249 14481 net.cpp:328] relu6 -> fc6 (in-place)
I1123 11:45:01.673255 14481 net.cpp:113] Setting up relu6
I1123 11:45:01.673260 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:01.673264 14481 layer_factory.hpp:74] Creating layer drop6
I1123 11:45:01.673269 14481 net.cpp:84] Creating Layer drop6
I1123 11:45:01.673271 14481 net.cpp:381] drop6 <- fc6
I1123 11:45:01.673275 14481 net.cpp:328] drop6 -> fc6 (in-place)
I1123 11:45:01.673282 14481 net.cpp:113] Setting up drop6
I1123 11:45:01.673290 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:01.673306 14481 layer_factory.hpp:74] Creating layer fc7
I1123 11:45:01.673321 14481 net.cpp:84] Creating Layer fc7
I1123 11:45:01.673331 14481 net.cpp:381] fc7 <- fc6
I1123 11:45:01.673344 14481 net.cpp:339] fc7 -> fc7
I1123 11:45:01.673360 14481 net.cpp:113] Setting up fc7
I1123 11:45:01.804086 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:01.804103 14481 layer_factory.hpp:74] Creating layer relu7
I1123 11:45:01.804112 14481 net.cpp:84] Creating Layer relu7
I1123 11:45:01.804116 14481 net.cpp:381] relu7 <- fc7
I1123 11:45:01.804121 14481 net.cpp:328] relu7 -> fc7 (in-place)
I1123 11:45:01.804128 14481 net.cpp:113] Setting up relu7
I1123 11:45:01.804132 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:01.804136 14481 layer_factory.hpp:74] Creating layer drop7
I1123 11:45:01.804141 14481 net.cpp:84] Creating Layer drop7
I1123 11:45:01.804155 14481 net.cpp:381] drop7 <- fc7
I1123 11:45:01.804168 14481 net.cpp:328] drop7 -> fc7 (in-place)
I1123 11:45:01.804181 14481 net.cpp:113] Setting up drop7
I1123 11:45:01.804195 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:01.804206 14481 layer_factory.hpp:74] Creating layer loss
I1123 11:45:04.757664 14481 net.cpp:84] Creating Layer loss
I1123 11:45:04.757699 14481 net.cpp:381] loss <- fc7
I1123 11:45:04.757719 14481 net.cpp:381] loss <- train_label
I1123 11:45:04.757732 14481 net.cpp:381] loss <- label
I1123 11:45:04.757755 14481 net.cpp:339] loss -> loss
I1123 11:45:04.757778 14481 net.cpp:113] Setting up loss
I1123 11:45:04.757869 14481 net.cpp:120] Top shape: 1 (1)
I1123 11:45:04.757884 14481 net.cpp:122]     with loss weight 1
I1123 11:45:04.757936 14481 net.cpp:167] loss needs backward computation.
I1123 11:45:04.757951 14481 net.cpp:167] drop7 needs backward computation.
I1123 11:45:04.757961 14481 net.cpp:167] relu7 needs backward computation.
I1123 11:45:04.757972 14481 net.cpp:167] fc7 needs backward computation.
I1123 11:45:04.757982 14481 net.cpp:167] drop6 needs backward computation.
I1123 11:45:04.757992 14481 net.cpp:167] relu6 needs backward computation.
I1123 11:45:04.758002 14481 net.cpp:167] fc6 needs backward computation.
I1123 11:45:04.758011 14481 net.cpp:167] pool5 needs backward computation.
I1123 11:45:04.758021 14481 net.cpp:167] relu5 needs backward computation.
I1123 11:45:04.758031 14481 net.cpp:167] conv5 needs backward computation.
I1123 11:45:04.758041 14481 net.cpp:167] relu4 needs backward computation.
I1123 11:45:04.758051 14481 net.cpp:167] conv4 needs backward computation.
I1123 11:45:04.758061 14481 net.cpp:167] relu3 needs backward computation.
I1123 11:45:04.758071 14481 net.cpp:167] conv3 needs backward computation.
I1123 11:45:04.758081 14481 net.cpp:167] norm2 needs backward computation.
I1123 11:45:04.758092 14481 net.cpp:167] pool2 needs backward computation.
I1123 11:45:04.758103 14481 net.cpp:167] relu2 needs backward computation.
I1123 11:45:04.758112 14481 net.cpp:167] conv2 needs backward computation.
I1123 11:45:04.758122 14481 net.cpp:167] norm1 needs backward computation.
I1123 11:45:04.758133 14481 net.cpp:167] pool1 needs backward computation.
I1123 11:45:04.758143 14481 net.cpp:167] relu1 needs backward computation.
I1123 11:45:04.758153 14481 net.cpp:167] conv1 needs backward computation.
I1123 11:45:04.758164 14481 net.cpp:169] train_label does not need backward computation.
I1123 11:45:04.758174 14481 net.cpp:169] data does not need backward computation.
I1123 11:45:04.758183 14481 net.cpp:205] This network produces output loss
I1123 11:45:04.758236 14481 net.cpp:446] Collecting Learning Rate and Weight Decay.
I1123 11:45:04.758260 14481 net.cpp:218] Network initialization done.
I1123 11:45:04.758270 14481 net.cpp:219] Memory required for data: 852858804
I1123 11:45:04.760247 14481 solver.cpp:167] Creating test net (#0) specified by net file: train_test_singleFrame_RGB.prototxt
I1123 11:45:04.760406 14481 net.cpp:258] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1123 11:45:04.760424 14481 net.cpp:258] The NetState phase (1) differed from the phase (0) specified by a rule in layer train_label
I1123 11:45:04.760483 14481 net.cpp:258] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I1123 11:45:04.761127 14481 net.cpp:42] Initializing net from parameters: 
name: "singleFrame_RGB"
state {
  phase: TEST
  stage: "test-on-test"
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 103.939
    mean_value: 116.779
    mean_value: 123.68
    flow: false
  }
  image_data_param {
    source: "/local-scratch/xla193/cluster_video_/output/UCF-101/list_frm-labelvect-fix-veri-1ft-random.txt"
    batch_size: 50
    shuffle: false
    new_height: 240
    new_width: 320
    root_folder: "frames/"
  }
}
layer {
  name: "test_label"
  type: "HDF5Data"
  top: "test_label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/cs/vml4/xla193/cross2_list/valid_label_fix_1-1.txt"
    batch_size: 50
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    kernel_size: 5
    group: 2
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "loss"
  type: "Python"
  bottom: "fc7"
  bottom: "test_label"
  bottom: "label"
  top: "loss"
  loss_weight: 1
  include {
    phase: TEST
  }
  python_param {
    module: "mylayers"
    layer: "HardTripletLossLayer"
  }
}
I1123 11:45:04.761441 14481 layer_factory.hpp:74] Creating layer data
I1123 11:45:04.761471 14481 net.cpp:84] Creating Layer data
I1123 11:45:04.761487 14481 net.cpp:339] data -> data
I1123 11:45:04.761513 14481 net.cpp:339] data -> label
I1123 11:45:04.761533 14481 net.cpp:113] Setting up data
I1123 11:45:04.761545 14481 image_data_layer.cpp:41] Opening file /local-scratch/xla193/cluster_video_/output/UCF-101/list_frm-labelvect-fix-veri-1ft-random.txt
I1123 11:45:04.782932 14481 image_data_layer.cpp:56] A total of 40535 images.
I1123 11:45:04.783702 14481 image_data_layer.cpp:86] output data size: 50,3,227,227
I1123 11:45:04.787710 14481 net.cpp:120] Top shape: 50 3 227 227 (7729350)
I1123 11:45:04.787717 14481 net.cpp:120] Top shape: 50 (50)
I1123 11:45:04.787724 14481 layer_factory.hpp:74] Creating layer test_label
I1123 11:45:04.787736 14481 net.cpp:84] Creating Layer test_label
I1123 11:45:04.787741 14481 net.cpp:339] test_label -> test_label
I1123 11:45:04.787753 14481 net.cpp:113] Setting up test_label
I1123 11:45:04.787756 14481 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: /cs/vml4/xla193/cross2_list/valid_label_fix_1-1.txt
I1123 11:45:04.788719 14481 hdf5_data_layer.cpp:94] Number of HDF5 files: 1
I1123 11:45:04.789620 14481 net.cpp:120] Top shape: 50 10 (500)
I1123 11:45:04.789628 14481 layer_factory.hpp:74] Creating layer conv1
I1123 11:45:04.789636 14481 net.cpp:84] Creating Layer conv1
I1123 11:45:04.789650 14481 net.cpp:381] conv1 <- data
I1123 11:45:04.789657 14481 net.cpp:339] conv1 -> conv1
I1123 11:45:04.789667 14481 net.cpp:113] Setting up conv1
I1123 11:45:04.789803 14481 net.cpp:120] Top shape: 50 96 111 111 (59140800)
I1123 11:45:04.789810 14481 layer_factory.hpp:74] Creating layer relu1
I1123 11:45:04.789818 14481 net.cpp:84] Creating Layer relu1
I1123 11:45:04.789820 14481 net.cpp:381] relu1 <- conv1
I1123 11:45:04.789825 14481 net.cpp:328] relu1 -> conv1 (in-place)
I1123 11:45:04.789829 14481 net.cpp:113] Setting up relu1
I1123 11:45:04.789844 14481 net.cpp:120] Top shape: 50 96 111 111 (59140800)
I1123 11:45:04.789860 14481 layer_factory.hpp:74] Creating layer pool1
I1123 11:45:04.789867 14481 net.cpp:84] Creating Layer pool1
I1123 11:45:04.789870 14481 net.cpp:381] pool1 <- conv1
I1123 11:45:04.789875 14481 net.cpp:339] pool1 -> pool1
I1123 11:45:04.789881 14481 net.cpp:113] Setting up pool1
I1123 11:45:04.789890 14481 net.cpp:120] Top shape: 50 96 55 55 (14520000)
I1123 11:45:04.789893 14481 layer_factory.hpp:74] Creating layer norm1
I1123 11:45:04.789899 14481 net.cpp:84] Creating Layer norm1
I1123 11:45:04.789901 14481 net.cpp:381] norm1 <- pool1
I1123 11:45:04.789906 14481 net.cpp:339] norm1 -> norm1
I1123 11:45:04.789911 14481 net.cpp:113] Setting up norm1
I1123 11:45:04.789921 14481 net.cpp:120] Top shape: 50 96 55 55 (14520000)
I1123 11:45:04.789923 14481 layer_factory.hpp:74] Creating layer conv2
I1123 11:45:04.789929 14481 net.cpp:84] Creating Layer conv2
I1123 11:45:04.789932 14481 net.cpp:381] conv2 <- norm1
I1123 11:45:04.789937 14481 net.cpp:339] conv2 -> conv2
I1123 11:45:04.789942 14481 net.cpp:113] Setting up conv2
I1123 11:45:04.794116 14481 net.cpp:120] Top shape: 50 384 26 26 (12979200)
I1123 11:45:04.794126 14481 layer_factory.hpp:74] Creating layer relu2
I1123 11:45:04.794131 14481 net.cpp:84] Creating Layer relu2
I1123 11:45:04.794133 14481 net.cpp:381] relu2 <- conv2
I1123 11:45:04.794138 14481 net.cpp:328] relu2 -> conv2 (in-place)
I1123 11:45:04.794142 14481 net.cpp:113] Setting up relu2
I1123 11:45:04.794147 14481 net.cpp:120] Top shape: 50 384 26 26 (12979200)
I1123 11:45:04.794150 14481 layer_factory.hpp:74] Creating layer pool2
I1123 11:45:04.794157 14481 net.cpp:84] Creating Layer pool2
I1123 11:45:04.794159 14481 net.cpp:381] pool2 <- conv2
I1123 11:45:04.794163 14481 net.cpp:339] pool2 -> pool2
I1123 11:45:04.794168 14481 net.cpp:113] Setting up pool2
I1123 11:45:04.794175 14481 net.cpp:120] Top shape: 50 384 13 13 (3244800)
I1123 11:45:04.794178 14481 layer_factory.hpp:74] Creating layer norm2
I1123 11:45:04.794183 14481 net.cpp:84] Creating Layer norm2
I1123 11:45:04.794186 14481 net.cpp:381] norm2 <- pool2
I1123 11:45:04.794190 14481 net.cpp:339] norm2 -> norm2
I1123 11:45:04.794195 14481 net.cpp:113] Setting up norm2
I1123 11:45:04.794201 14481 net.cpp:120] Top shape: 50 384 13 13 (3244800)
I1123 11:45:04.794205 14481 layer_factory.hpp:74] Creating layer conv3
I1123 11:45:04.794211 14481 net.cpp:84] Creating Layer conv3
I1123 11:45:04.794214 14481 net.cpp:381] conv3 <- norm2
I1123 11:45:04.794219 14481 net.cpp:339] conv3 -> conv3
I1123 11:45:04.794224 14481 net.cpp:113] Setting up conv3
I1123 11:45:04.809172 14481 net.cpp:120] Top shape: 50 512 13 13 (4326400)
I1123 11:45:04.809190 14481 layer_factory.hpp:74] Creating layer relu3
I1123 11:45:04.809197 14481 net.cpp:84] Creating Layer relu3
I1123 11:45:04.809201 14481 net.cpp:381] relu3 <- conv3
I1123 11:45:04.809207 14481 net.cpp:328] relu3 -> conv3 (in-place)
I1123 11:45:04.809213 14481 net.cpp:113] Setting up relu3
I1123 11:45:04.809217 14481 net.cpp:120] Top shape: 50 512 13 13 (4326400)
I1123 11:45:04.809221 14481 layer_factory.hpp:74] Creating layer conv4
I1123 11:45:04.809226 14481 net.cpp:84] Creating Layer conv4
I1123 11:45:04.809229 14481 net.cpp:381] conv4 <- conv3
I1123 11:45:04.809233 14481 net.cpp:339] conv4 -> conv4
I1123 11:45:04.809239 14481 net.cpp:113] Setting up conv4
I1123 11:45:04.819486 14481 net.cpp:120] Top shape: 50 512 13 13 (4326400)
I1123 11:45:04.819501 14481 layer_factory.hpp:74] Creating layer relu4
I1123 11:45:04.819511 14481 net.cpp:84] Creating Layer relu4
I1123 11:45:04.819515 14481 net.cpp:381] relu4 <- conv4
I1123 11:45:04.819521 14481 net.cpp:328] relu4 -> conv4 (in-place)
I1123 11:45:04.819528 14481 net.cpp:113] Setting up relu4
I1123 11:45:04.819533 14481 net.cpp:120] Top shape: 50 512 13 13 (4326400)
I1123 11:45:04.819535 14481 layer_factory.hpp:74] Creating layer conv5
I1123 11:45:04.819545 14481 net.cpp:84] Creating Layer conv5
I1123 11:45:04.819548 14481 net.cpp:381] conv5 <- conv4
I1123 11:45:04.819555 14481 net.cpp:339] conv5 -> conv5
I1123 11:45:04.819561 14481 net.cpp:113] Setting up conv5
I1123 11:45:04.827141 14481 net.cpp:120] Top shape: 50 384 13 13 (3244800)
I1123 11:45:04.827157 14481 layer_factory.hpp:74] Creating layer relu5
I1123 11:45:04.827164 14481 net.cpp:84] Creating Layer relu5
I1123 11:45:04.827168 14481 net.cpp:381] relu5 <- conv5
I1123 11:45:04.827173 14481 net.cpp:328] relu5 -> conv5 (in-place)
I1123 11:45:04.827189 14481 net.cpp:113] Setting up relu5
I1123 11:45:04.827194 14481 net.cpp:120] Top shape: 50 384 13 13 (3244800)
I1123 11:45:04.827198 14481 layer_factory.hpp:74] Creating layer pool5
I1123 11:45:04.827208 14481 net.cpp:84] Creating Layer pool5
I1123 11:45:04.827211 14481 net.cpp:381] pool5 <- conv5
I1123 11:45:04.827216 14481 net.cpp:339] pool5 -> pool5
I1123 11:45:04.827222 14481 net.cpp:113] Setting up pool5
I1123 11:45:04.827230 14481 net.cpp:120] Top shape: 50 384 6 6 (691200)
I1123 11:45:04.827234 14481 layer_factory.hpp:74] Creating layer fc6
I1123 11:45:04.827241 14481 net.cpp:84] Creating Layer fc6
I1123 11:45:04.827244 14481 net.cpp:381] fc6 <- pool5
I1123 11:45:04.827250 14481 net.cpp:339] fc6 -> fc6
I1123 11:45:04.827255 14481 net.cpp:113] Setting up fc6
I1123 11:45:05.268069 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:05.268086 14481 layer_factory.hpp:74] Creating layer relu6
I1123 11:45:05.268095 14481 net.cpp:84] Creating Layer relu6
I1123 11:45:05.268100 14481 net.cpp:381] relu6 <- fc6
I1123 11:45:05.268105 14481 net.cpp:328] relu6 -> fc6 (in-place)
I1123 11:45:05.268110 14481 net.cpp:113] Setting up relu6
I1123 11:45:05.268115 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:05.268117 14481 layer_factory.hpp:74] Creating layer drop6
I1123 11:45:05.268122 14481 net.cpp:84] Creating Layer drop6
I1123 11:45:05.268126 14481 net.cpp:381] drop6 <- fc6
I1123 11:45:05.268129 14481 net.cpp:328] drop6 -> fc6 (in-place)
I1123 11:45:05.268133 14481 net.cpp:113] Setting up drop6
I1123 11:45:05.268139 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:05.268142 14481 layer_factory.hpp:74] Creating layer fc7
I1123 11:45:05.268149 14481 net.cpp:84] Creating Layer fc7
I1123 11:45:05.268152 14481 net.cpp:381] fc7 <- fc6
I1123 11:45:05.268157 14481 net.cpp:339] fc7 -> fc7
I1123 11:45:05.268163 14481 net.cpp:113] Setting up fc7
I1123 11:45:05.399416 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:05.399435 14481 layer_factory.hpp:74] Creating layer relu7
I1123 11:45:05.399443 14481 net.cpp:84] Creating Layer relu7
I1123 11:45:05.399447 14481 net.cpp:381] relu7 <- fc7
I1123 11:45:05.399452 14481 net.cpp:328] relu7 -> fc7 (in-place)
I1123 11:45:05.399458 14481 net.cpp:113] Setting up relu7
I1123 11:45:05.399462 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:05.399464 14481 layer_factory.hpp:74] Creating layer drop7
I1123 11:45:05.399471 14481 net.cpp:84] Creating Layer drop7
I1123 11:45:05.399472 14481 net.cpp:381] drop7 <- fc7
I1123 11:45:05.399476 14481 net.cpp:328] drop7 -> fc7 (in-place)
I1123 11:45:05.399479 14481 net.cpp:113] Setting up drop7
I1123 11:45:05.399484 14481 net.cpp:120] Top shape: 50 4096 (204800)
I1123 11:45:05.399487 14481 layer_factory.hpp:74] Creating layer loss
I1123 11:45:05.399559 14481 net.cpp:84] Creating Layer loss
I1123 11:45:05.399562 14481 net.cpp:381] loss <- fc7
I1123 11:45:05.399566 14481 net.cpp:381] loss <- test_label
I1123 11:45:05.399570 14481 net.cpp:381] loss <- label
I1123 11:45:05.399576 14481 net.cpp:339] loss -> loss
I1123 11:45:05.399581 14481 net.cpp:113] Setting up loss
I1123 11:45:05.399608 14481 net.cpp:120] Top shape: 1 (1)
I1123 11:45:05.399611 14481 net.cpp:122]     with loss weight 1
I1123 11:45:05.399622 14481 net.cpp:167] loss needs backward computation.
I1123 11:45:05.399626 14481 net.cpp:167] drop7 needs backward computation.
I1123 11:45:05.399628 14481 net.cpp:167] relu7 needs backward computation.
I1123 11:45:05.399631 14481 net.cpp:167] fc7 needs backward computation.
I1123 11:45:05.399633 14481 net.cpp:167] drop6 needs backward computation.
I1123 11:45:05.399636 14481 net.cpp:167] relu6 needs backward computation.
I1123 11:45:05.399639 14481 net.cpp:167] fc6 needs backward computation.
I1123 11:45:05.399642 14481 net.cpp:167] pool5 needs backward computation.
I1123 11:45:05.399646 14481 net.cpp:167] relu5 needs backward computation.
I1123 11:45:05.399648 14481 net.cpp:167] conv5 needs backward computation.
I1123 11:45:05.399652 14481 net.cpp:167] relu4 needs backward computation.
I1123 11:45:05.399653 14481 net.cpp:167] conv4 needs backward computation.
I1123 11:45:05.399657 14481 net.cpp:167] relu3 needs backward computation.
I1123 11:45:05.399659 14481 net.cpp:167] conv3 needs backward computation.
I1123 11:45:05.399662 14481 net.cpp:167] norm2 needs backward computation.
I1123 11:45:05.399665 14481 net.cpp:167] pool2 needs backward computation.
I1123 11:45:05.399668 14481 net.cpp:167] relu2 needs backward computation.
I1123 11:45:05.399672 14481 net.cpp:167] conv2 needs backward computation.
I1123 11:45:05.399674 14481 net.cpp:167] norm1 needs backward computation.
I1123 11:45:05.399677 14481 net.cpp:167] pool1 needs backward computation.
I1123 11:45:05.399680 14481 net.cpp:167] relu1 needs backward computation.
I1123 11:45:05.399683 14481 net.cpp:167] conv1 needs backward computation.
I1123 11:45:05.399687 14481 net.cpp:169] test_label does not need backward computation.
I1123 11:45:05.399689 14481 net.cpp:169] data does not need backward computation.
I1123 11:45:05.399691 14481 net.cpp:205] This network produces output loss
I1123 11:45:05.399703 14481 net.cpp:446] Collecting Learning Rate and Weight Decay.
I1123 11:45:05.399709 14481 net.cpp:218] Network initialization done.
I1123 11:45:05.399713 14481 net.cpp:219] Memory required for data: 852858804
I1123 11:45:05.399796 14481 solver.cpp:55] Solver scaffolding done.
I1123 11:45:05.399830 14481 caffe.cpp:93] Finetuning from /cs/vml4/xla193/cross1/all-8_iter_2880.caffemodel
I1123 11:45:38.600304 14481 solver.cpp:272] Solving singleFrame_RGB
I1123 11:45:38.600319 14481 solver.cpp:273] Learning Rate Policy: step
I1123 11:45:39.032230 14481 solver.cpp:231] Iteration 0, loss = 307.48
I1123 11:45:39.032253 14481 solver.cpp:246]     Train net output #0: loss = 307.48 (* 1 = 307.48 loss)
I1123 11:45:39.032265 14481 solver.cpp:545] Iteration 0, lr = 1e-08
I1123 11:45:48.690053 14481 solver.cpp:231] Iteration 20, loss = 521.59
I1123 11:45:48.690078 14481 solver.cpp:246]     Train net output #0: loss = 521.59 (* 1 = 521.59 loss)
I1123 11:45:48.690083 14481 solver.cpp:545] Iteration 20, lr = 1e-08
I1123 11:45:58.481422 14481 solver.cpp:231] Iteration 40, loss = 119.452
I1123 11:45:58.481446 14481 solver.cpp:246]     Train net output #0: loss = 119.452 (* 1 = 119.452 loss)
I1123 11:45:58.481451 14481 solver.cpp:545] Iteration 40, lr = 1e-08
I1123 11:46:08.243854 14481 solver.cpp:231] Iteration 60, loss = 246.912
I1123 11:46:08.243877 14481 solver.cpp:246]     Train net output #0: loss = 246.912 (* 1 = 246.912 loss)
I1123 11:46:08.243883 14481 solver.cpp:545] Iteration 60, lr = 1e-08
I1123 11:46:17.964658 14481 solver.cpp:231] Iteration 80, loss = 161.13
I1123 11:46:17.964681 14481 solver.cpp:246]     Train net output #0: loss = 161.129 (* 1 = 161.129 loss)
I1123 11:46:17.964686 14481 solver.cpp:545] Iteration 80, lr = 1e-08
I1123 11:46:27.713125 14481 solver.cpp:231] Iteration 100, loss = 4.58286
I1123 11:46:27.713147 14481 solver.cpp:246]     Train net output #0: loss = 4.58277 (* 1 = 4.58277 loss)
I1123 11:46:27.713152 14481 solver.cpp:545] Iteration 100, lr = 1e-08
I1123 11:46:37.379447 14481 solver.cpp:231] Iteration 120, loss = 164.233
I1123 11:46:37.379472 14481 solver.cpp:246]     Train net output #0: loss = 164.233 (* 1 = 164.233 loss)
I1123 11:46:37.379477 14481 solver.cpp:545] Iteration 120, lr = 1e-08
I1123 11:46:47.086002 14481 solver.cpp:231] Iteration 140, loss = 102.843
I1123 11:46:47.086040 14481 solver.cpp:246]     Train net output #0: loss = 102.843 (* 1 = 102.843 loss)
I1123 11:46:47.086056 14481 solver.cpp:545] Iteration 140, lr = 1e-08
I1123 11:46:56.789351 14481 solver.cpp:231] Iteration 160, loss = 96.9742
I1123 11:46:56.789374 14481 solver.cpp:246]     Train net output #0: loss = 96.9741 (* 1 = 96.9741 loss)
I1123 11:46:56.789379 14481 solver.cpp:545] Iteration 160, lr = 1e-08
I1123 11:47:06.467420 14481 solver.cpp:231] Iteration 180, loss = 1.76833
I1123 11:47:06.467442 14481 solver.cpp:246]     Train net output #0: loss = 1.7682 (* 1 = 1.7682 loss)
I1123 11:47:06.467447 14481 solver.cpp:545] Iteration 180, lr = 1e-08
I1123 11:47:16.229941 14481 solver.cpp:231] Iteration 200, loss = 154.604
I1123 11:47:16.229965 14481 solver.cpp:246]     Train net output #0: loss = 154.604 (* 1 = 154.604 loss)
I1123 11:47:16.229971 14481 solver.cpp:545] Iteration 200, lr = 1e-08
I1123 11:47:26.054946 14481 solver.cpp:231] Iteration 220, loss = 105.047
I1123 11:47:26.054971 14481 solver.cpp:246]     Train net output #0: loss = 105.047 (* 1 = 105.047 loss)
I1123 11:47:26.054976 14481 solver.cpp:545] Iteration 220, lr = 1e-08
I1123 11:47:35.768492 14481 solver.cpp:231] Iteration 240, loss = 62.9509
I1123 11:47:35.768515 14481 solver.cpp:246]     Train net output #0: loss = 62.9508 (* 1 = 62.9508 loss)
I1123 11:47:35.768520 14481 solver.cpp:545] Iteration 240, lr = 1e-08
I1123 11:47:45.513514 14481 solver.cpp:231] Iteration 260, loss = 35.1101
I1123 11:47:45.513540 14481 solver.cpp:246]     Train net output #0: loss = 35.11 (* 1 = 35.11 loss)
I1123 11:47:45.513545 14481 solver.cpp:545] Iteration 260, lr = 1e-08
I1123 11:47:55.253855 14481 solver.cpp:231] Iteration 280, loss = 32.7669
I1123 11:47:55.253880 14481 solver.cpp:246]     Train net output #0: loss = 32.7668 (* 1 = 32.7668 loss)
I1123 11:47:55.253885 14481 solver.cpp:545] Iteration 280, lr = 1e-08
I1123 11:48:05.055893 14481 solver.cpp:231] Iteration 300, loss = 7.14034
I1123 11:48:05.055917 14481 solver.cpp:246]     Train net output #0: loss = 7.14021 (* 1 = 7.14021 loss)
I1123 11:48:05.055922 14481 solver.cpp:545] Iteration 300, lr = 1e-08
I1123 11:48:14.960366 14481 solver.cpp:231] Iteration 320, loss = 47.0477
I1123 11:48:14.960391 14481 solver.cpp:246]     Train net output #0: loss = 47.0476 (* 1 = 47.0476 loss)
I1123 11:48:14.960396 14481 solver.cpp:545] Iteration 320, lr = 1e-08
I1123 11:48:24.635319 14481 solver.cpp:231] Iteration 340, loss = 45.9803
I1123 11:48:24.635344 14481 solver.cpp:246]     Train net output #0: loss = 45.9801 (* 1 = 45.9801 loss)
I1123 11:48:24.635349 14481 solver.cpp:545] Iteration 340, lr = 1e-08
I1123 11:48:34.271960 14481 solver.cpp:231] Iteration 360, loss = 101.973
I1123 11:48:34.271986 14481 solver.cpp:246]     Train net output #0: loss = 101.973 (* 1 = 101.973 loss)
I1123 11:48:34.271991 14481 solver.cpp:545] Iteration 360, lr = 1e-08
I1123 11:48:44.108544 14481 solver.cpp:231] Iteration 380, loss = 87.0644
I1123 11:48:44.108584 14481 solver.cpp:246]     Train net output #0: loss = 87.0643 (* 1 = 87.0643 loss)
I1123 11:48:44.108590 14481 solver.cpp:545] Iteration 380, lr = 1e-08
I1123 11:48:53.871140 14481 solver.cpp:231] Iteration 400, loss = 0.000110626
I1123 11:48:53.871162 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:48:53.871168 14481 solver.cpp:545] Iteration 400, lr = 1e-08
I1123 11:49:03.675174 14481 solver.cpp:231] Iteration 420, loss = 0.000106812
I1123 11:49:03.675199 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:49:03.675204 14481 solver.cpp:545] Iteration 420, lr = 1e-08
I1123 11:49:13.352035 14481 solver.cpp:231] Iteration 440, loss = 0.000106812
I1123 11:49:13.352058 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:49:13.352064 14481 solver.cpp:545] Iteration 440, lr = 1e-08
I1123 11:49:22.958407 14481 solver.cpp:231] Iteration 460, loss = 14.15
I1123 11:49:22.958431 14481 solver.cpp:246]     Train net output #0: loss = 14.1498 (* 1 = 14.1498 loss)
I1123 11:49:22.958437 14481 solver.cpp:545] Iteration 460, lr = 1e-08
I1123 11:49:32.597167 14481 solver.cpp:231] Iteration 480, loss = 44.641
I1123 11:49:32.597192 14481 solver.cpp:246]     Train net output #0: loss = 44.6409 (* 1 = 44.6409 loss)
I1123 11:49:32.597198 14481 solver.cpp:545] Iteration 480, lr = 1e-08
I1123 11:49:42.289134 14481 solver.cpp:231] Iteration 500, loss = 5.503
I1123 11:49:42.289156 14481 solver.cpp:246]     Train net output #0: loss = 5.5029 (* 1 = 5.5029 loss)
I1123 11:49:42.289162 14481 solver.cpp:545] Iteration 500, lr = 1e-08
I1123 11:49:52.107975 14481 solver.cpp:231] Iteration 520, loss = 36.7904
I1123 11:49:52.107998 14481 solver.cpp:246]     Train net output #0: loss = 36.7903 (* 1 = 36.7903 loss)
I1123 11:49:52.108003 14481 solver.cpp:545] Iteration 520, lr = 1e-08
I1123 11:50:01.758514 14481 solver.cpp:231] Iteration 540, loss = 12.4749
I1123 11:50:01.758538 14481 solver.cpp:246]     Train net output #0: loss = 12.4748 (* 1 = 12.4748 loss)
I1123 11:50:01.758543 14481 solver.cpp:545] Iteration 540, lr = 1e-08
I1123 11:50:11.418902 14481 solver.cpp:231] Iteration 560, loss = 5.968
I1123 11:50:11.418925 14481 solver.cpp:246]     Train net output #0: loss = 5.9679 (* 1 = 5.9679 loss)
I1123 11:50:11.418929 14481 solver.cpp:545] Iteration 560, lr = 1e-08
I1123 11:50:21.183554 14481 solver.cpp:231] Iteration 580, loss = 203.227
I1123 11:50:21.183578 14481 solver.cpp:246]     Train net output #0: loss = 203.227 (* 1 = 203.227 loss)
I1123 11:50:21.183603 14481 solver.cpp:545] Iteration 580, lr = 1e-08
I1123 11:50:30.903489 14481 solver.cpp:231] Iteration 600, loss = 98.1294
I1123 11:50:30.903512 14481 solver.cpp:246]     Train net output #0: loss = 98.1293 (* 1 = 98.1293 loss)
I1123 11:50:30.903517 14481 solver.cpp:545] Iteration 600, lr = 1e-08
I1123 11:50:40.582815 14481 solver.cpp:231] Iteration 620, loss = 23.928
I1123 11:50:40.582839 14481 solver.cpp:246]     Train net output #0: loss = 23.9279 (* 1 = 23.9279 loss)
I1123 11:50:40.582845 14481 solver.cpp:545] Iteration 620, lr = 1e-08
I1123 11:50:50.256853 14481 solver.cpp:231] Iteration 640, loss = 36.6672
I1123 11:50:50.256878 14481 solver.cpp:246]     Train net output #0: loss = 36.6671 (* 1 = 36.6671 loss)
I1123 11:50:50.256883 14481 solver.cpp:545] Iteration 640, lr = 1e-08
I1123 11:51:00.069077 14481 solver.cpp:231] Iteration 660, loss = 4.70176
I1123 11:51:00.069098 14481 solver.cpp:246]     Train net output #0: loss = 4.70165 (* 1 = 4.70165 loss)
I1123 11:51:00.069103 14481 solver.cpp:545] Iteration 660, lr = 1e-08
I1123 11:51:09.748843 14481 solver.cpp:231] Iteration 680, loss = 83.8501
I1123 11:51:09.748867 14481 solver.cpp:246]     Train net output #0: loss = 83.8499 (* 1 = 83.8499 loss)
I1123 11:51:09.748873 14481 solver.cpp:545] Iteration 680, lr = 1e-08
I1123 11:51:19.651617 14481 solver.cpp:231] Iteration 700, loss = 4.4169
I1123 11:51:19.651653 14481 solver.cpp:246]     Train net output #0: loss = 4.41681 (* 1 = 4.41681 loss)
I1123 11:51:19.651659 14481 solver.cpp:545] Iteration 700, lr = 1e-08
I1123 11:51:29.453397 14481 solver.cpp:231] Iteration 720, loss = 2.58341
I1123 11:51:29.453434 14481 solver.cpp:246]     Train net output #0: loss = 2.58332 (* 1 = 2.58332 loss)
I1123 11:51:29.453441 14481 solver.cpp:545] Iteration 720, lr = 1e-08
I1123 11:51:39.233181 14481 solver.cpp:231] Iteration 740, loss = 37.3442
I1123 11:51:39.233220 14481 solver.cpp:246]     Train net output #0: loss = 37.3441 (* 1 = 37.3441 loss)
I1123 11:51:39.233227 14481 solver.cpp:545] Iteration 740, lr = 1e-08
I1123 11:51:49.038573 14481 solver.cpp:231] Iteration 760, loss = 9.10759e-05
I1123 11:51:49.038606 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:51:49.038612 14481 solver.cpp:545] Iteration 760, lr = 1e-08
I1123 11:51:58.732700 14481 solver.cpp:231] Iteration 780, loss = 27.4835
I1123 11:51:58.732743 14481 solver.cpp:246]     Train net output #0: loss = 27.4834 (* 1 = 27.4834 loss)
I1123 11:51:58.732750 14481 solver.cpp:545] Iteration 780, lr = 1e-08
I1123 11:52:08.593752 14481 solver.cpp:231] Iteration 800, loss = 61.6229
I1123 11:52:08.593793 14481 solver.cpp:246]     Train net output #0: loss = 61.6228 (* 1 = 61.6228 loss)
I1123 11:52:08.593799 14481 solver.cpp:545] Iteration 800, lr = 1e-08
I1123 11:52:13.851862 14481 solver.cpp:415] Snapshotting to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_811.caffemodel
I1123 11:52:14.312999 14481 solver.cpp:423] Snapshotting solver state to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_811.solverstate
I1123 11:52:19.313895 14481 solver.cpp:231] Iteration 820, loss = 8.87121
I1123 11:52:19.313917 14481 solver.cpp:246]     Train net output #0: loss = 8.87111 (* 1 = 8.87111 loss)
I1123 11:52:19.313923 14481 solver.cpp:545] Iteration 820, lr = 1e-08
I1123 11:52:29.033356 14481 solver.cpp:231] Iteration 840, loss = 70.2827
I1123 11:52:29.033393 14481 solver.cpp:246]     Train net output #0: loss = 70.2826 (* 1 = 70.2826 loss)
I1123 11:52:29.033399 14481 solver.cpp:545] Iteration 840, lr = 1e-08
I1123 11:52:38.835881 14481 solver.cpp:231] Iteration 860, loss = 0.000112534
I1123 11:52:38.835908 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:52:38.835913 14481 solver.cpp:545] Iteration 860, lr = 1e-08
I1123 11:52:48.633677 14481 solver.cpp:231] Iteration 880, loss = 6.99205
I1123 11:52:48.633709 14481 solver.cpp:246]     Train net output #0: loss = 6.99194 (* 1 = 6.99194 loss)
I1123 11:52:48.633715 14481 solver.cpp:545] Iteration 880, lr = 1e-08
I1123 11:52:58.440789 14481 solver.cpp:231] Iteration 900, loss = 8.88074
I1123 11:52:58.440812 14481 solver.cpp:246]     Train net output #0: loss = 8.88064 (* 1 = 8.88064 loss)
I1123 11:52:58.440817 14481 solver.cpp:545] Iteration 900, lr = 1e-08
I1123 11:53:08.197399 14481 solver.cpp:231] Iteration 920, loss = 0.000102043
I1123 11:53:08.197425 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:53:08.197430 14481 solver.cpp:545] Iteration 920, lr = 1e-08
I1123 11:53:17.860565 14481 solver.cpp:231] Iteration 940, loss = 9.52482e-05
I1123 11:53:17.860589 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:53:17.860595 14481 solver.cpp:545] Iteration 940, lr = 1e-08
I1123 11:53:27.619724 14481 solver.cpp:231] Iteration 960, loss = 33.2797
I1123 11:53:27.619748 14481 solver.cpp:246]     Train net output #0: loss = 33.2796 (* 1 = 33.2796 loss)
I1123 11:53:27.619753 14481 solver.cpp:545] Iteration 960, lr = 1e-08
I1123 11:53:37.290115 14481 solver.cpp:231] Iteration 980, loss = 1.39384
I1123 11:53:37.290138 14481 solver.cpp:246]     Train net output #0: loss = 1.39374 (* 1 = 1.39374 loss)
I1123 11:53:37.290143 14481 solver.cpp:545] Iteration 980, lr = 1e-08
I1123 11:53:47.044986 14481 solver.cpp:231] Iteration 1000, loss = 9.72748e-05
I1123 11:53:47.045011 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:53:47.045017 14481 solver.cpp:545] Iteration 1000, lr = 1e-08
I1123 11:53:56.754426 14481 solver.cpp:231] Iteration 1020, loss = 18.0197
I1123 11:53:56.754448 14481 solver.cpp:246]     Train net output #0: loss = 18.0196 (* 1 = 18.0196 loss)
I1123 11:53:56.754454 14481 solver.cpp:545] Iteration 1020, lr = 1e-08
I1123 11:54:06.604220 14481 solver.cpp:231] Iteration 1040, loss = 21.5556
I1123 11:54:06.604245 14481 solver.cpp:246]     Train net output #0: loss = 21.5555 (* 1 = 21.5555 loss)
I1123 11:54:06.604250 14481 solver.cpp:545] Iteration 1040, lr = 1e-08
I1123 11:54:16.314036 14481 solver.cpp:231] Iteration 1060, loss = 9.34601e-05
I1123 11:54:16.314060 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:54:16.314065 14481 solver.cpp:545] Iteration 1060, lr = 1e-08
I1123 11:54:26.063993 14481 solver.cpp:231] Iteration 1080, loss = 5.85833
I1123 11:54:26.064016 14481 solver.cpp:246]     Train net output #0: loss = 5.85824 (* 1 = 5.85824 loss)
I1123 11:54:26.064021 14481 solver.cpp:545] Iteration 1080, lr = 1e-08
I1123 11:54:35.806726 14481 solver.cpp:231] Iteration 1100, loss = 9.27448e-05
I1123 11:54:35.806748 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:54:35.806754 14481 solver.cpp:545] Iteration 1100, lr = 1e-08
I1123 11:54:45.488370 14481 solver.cpp:231] Iteration 1120, loss = 0.631461
I1123 11:54:45.488394 14481 solver.cpp:246]     Train net output #0: loss = 0.631369 (* 1 = 0.631369 loss)
I1123 11:54:45.488399 14481 solver.cpp:545] Iteration 1120, lr = 1e-08
I1123 11:54:55.115770 14481 solver.cpp:231] Iteration 1140, loss = 9.29385e-05
I1123 11:54:55.115793 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:54:55.115798 14481 solver.cpp:545] Iteration 1140, lr = 1e-08
I1123 11:55:04.742141 14481 solver.cpp:231] Iteration 1160, loss = 27.0313
I1123 11:55:04.742164 14481 solver.cpp:246]     Train net output #0: loss = 27.0312 (* 1 = 27.0312 loss)
I1123 11:55:04.742171 14481 solver.cpp:545] Iteration 1160, lr = 1e-08
I1123 11:55:14.481839 14481 solver.cpp:231] Iteration 1180, loss = 18.1493
I1123 11:55:14.481864 14481 solver.cpp:246]     Train net output #0: loss = 18.1492 (* 1 = 18.1492 loss)
I1123 11:55:14.481870 14481 solver.cpp:545] Iteration 1180, lr = 1e-08
I1123 11:55:24.209816 14481 solver.cpp:231] Iteration 1200, loss = 9.82285e-05
I1123 11:55:24.209839 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:55:24.209844 14481 solver.cpp:545] Iteration 1200, lr = 1e-08
I1123 11:55:33.924083 14481 solver.cpp:231] Iteration 1220, loss = 28.9362
I1123 11:55:33.924108 14481 solver.cpp:246]     Train net output #0: loss = 28.9361 (* 1 = 28.9361 loss)
I1123 11:55:33.924114 14481 solver.cpp:545] Iteration 1220, lr = 1e-08
I1123 11:55:43.551630 14481 solver.cpp:231] Iteration 1240, loss = 21.9523
I1123 11:55:43.551651 14481 solver.cpp:246]     Train net output #0: loss = 21.9522 (* 1 = 21.9522 loss)
I1123 11:55:43.551657 14481 solver.cpp:545] Iteration 1240, lr = 1e-08
I1123 11:55:53.160912 14481 solver.cpp:231] Iteration 1260, loss = 9.15527e-05
I1123 11:55:53.160956 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:55:53.160962 14481 solver.cpp:545] Iteration 1260, lr = 1e-08
I1123 11:56:02.835280 14481 solver.cpp:231] Iteration 1280, loss = 9.15527e-05
I1123 11:56:02.835304 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:56:02.835309 14481 solver.cpp:545] Iteration 1280, lr = 1e-08
I1123 11:56:12.495010 14481 solver.cpp:231] Iteration 1300, loss = 0.61652
I1123 11:56:12.495034 14481 solver.cpp:246]     Train net output #0: loss = 0.616427 (* 1 = 0.616427 loss)
I1123 11:56:12.495039 14481 solver.cpp:545] Iteration 1300, lr = 1e-08
I1123 11:56:22.319972 14481 solver.cpp:231] Iteration 1320, loss = 21.4439
I1123 11:56:22.319995 14481 solver.cpp:246]     Train net output #0: loss = 21.4438 (* 1 = 21.4438 loss)
I1123 11:56:22.320000 14481 solver.cpp:545] Iteration 1320, lr = 1e-08
I1123 11:56:31.976549 14481 solver.cpp:231] Iteration 1340, loss = 9.15527e-05
I1123 11:56:31.976574 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:56:31.976579 14481 solver.cpp:545] Iteration 1340, lr = 1e-08
I1123 11:56:41.619691 14481 solver.cpp:231] Iteration 1360, loss = 72.5157
I1123 11:56:41.619720 14481 solver.cpp:246]     Train net output #0: loss = 72.5156 (* 1 = 72.5156 loss)
I1123 11:56:41.619726 14481 solver.cpp:545] Iteration 1360, lr = 1e-08
I1123 11:56:51.271070 14481 solver.cpp:231] Iteration 1380, loss = 45.3271
I1123 11:56:51.271095 14481 solver.cpp:246]     Train net output #0: loss = 45.327 (* 1 = 45.327 loss)
I1123 11:56:51.271100 14481 solver.cpp:545] Iteration 1380, lr = 1e-08
I1123 11:57:00.981415 14481 solver.cpp:231] Iteration 1400, loss = 2.79431
I1123 11:57:00.981438 14481 solver.cpp:246]     Train net output #0: loss = 2.79421 (* 1 = 2.79421 loss)
I1123 11:57:00.981444 14481 solver.cpp:545] Iteration 1400, lr = 1e-08
I1123 11:57:10.625383 14481 solver.cpp:231] Iteration 1420, loss = 35.9022
I1123 11:57:10.625411 14481 solver.cpp:246]     Train net output #0: loss = 35.9021 (* 1 = 35.9021 loss)
I1123 11:57:10.625416 14481 solver.cpp:545] Iteration 1420, lr = 1e-08
I1123 11:57:20.228369 14481 solver.cpp:231] Iteration 1440, loss = 0.804901
I1123 11:57:20.228394 14481 solver.cpp:246]     Train net output #0: loss = 0.804805 (* 1 = 0.804805 loss)
I1123 11:57:20.228399 14481 solver.cpp:545] Iteration 1440, lr = 1e-08
I1123 11:57:30.017784 14481 solver.cpp:231] Iteration 1460, loss = 15.0271
I1123 11:57:30.017809 14481 solver.cpp:246]     Train net output #0: loss = 15.027 (* 1 = 15.027 loss)
I1123 11:57:30.017815 14481 solver.cpp:545] Iteration 1460, lr = 1e-08
I1123 11:57:39.651237 14481 solver.cpp:231] Iteration 1480, loss = 5.06066
I1123 11:57:39.651260 14481 solver.cpp:246]     Train net output #0: loss = 5.06057 (* 1 = 5.06057 loss)
I1123 11:57:39.651265 14481 solver.cpp:545] Iteration 1480, lr = 1e-08
I1123 11:57:49.395817 14481 solver.cpp:231] Iteration 1500, loss = 8.55579
I1123 11:57:49.395841 14481 solver.cpp:246]     Train net output #0: loss = 8.55569 (* 1 = 8.55569 loss)
I1123 11:57:49.395864 14481 solver.cpp:545] Iteration 1500, lr = 1e-08
I1123 11:57:59.283334 14481 solver.cpp:231] Iteration 1520, loss = 20.3152
I1123 11:57:59.283363 14481 solver.cpp:246]     Train net output #0: loss = 20.3152 (* 1 = 20.3152 loss)
I1123 11:57:59.283370 14481 solver.cpp:545] Iteration 1520, lr = 1e-08
I1123 11:58:08.930441 14481 solver.cpp:231] Iteration 1540, loss = 5.37628
I1123 11:58:08.930469 14481 solver.cpp:246]     Train net output #0: loss = 5.3762 (* 1 = 5.3762 loss)
I1123 11:58:08.930474 14481 solver.cpp:545] Iteration 1540, lr = 1e-08
I1123 11:58:18.598677 14481 solver.cpp:231] Iteration 1560, loss = 2.48607
I1123 11:58:18.598700 14481 solver.cpp:246]     Train net output #0: loss = 2.48599 (* 1 = 2.48599 loss)
I1123 11:58:18.598704 14481 solver.cpp:545] Iteration 1560, lr = 1e-08
I1123 11:58:28.249022 14481 solver.cpp:231] Iteration 1580, loss = 0.786912
I1123 11:58:28.249045 14481 solver.cpp:246]     Train net output #0: loss = 0.786828 (* 1 = 0.786828 loss)
I1123 11:58:28.249068 14481 solver.cpp:545] Iteration 1580, lr = 1e-08
I1123 11:58:37.922907 14481 solver.cpp:231] Iteration 1600, loss = 2.74214
I1123 11:58:37.922931 14481 solver.cpp:246]     Train net output #0: loss = 2.74205 (* 1 = 2.74205 loss)
I1123 11:58:37.922937 14481 solver.cpp:545] Iteration 1600, lr = 1e-08
I1123 11:58:47.645841 14481 solver.cpp:231] Iteration 1620, loss = 52.416
I1123 11:58:47.645866 14481 solver.cpp:246]     Train net output #0: loss = 52.4159 (* 1 = 52.4159 loss)
I1123 11:58:47.645871 14481 solver.cpp:545] Iteration 1620, lr = 1e-08
I1123 11:58:48.442643 14481 solver.cpp:415] Snapshotting to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_1622.caffemodel
I1123 11:58:48.867902 14481 solver.cpp:423] Snapshotting solver state to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_1622.solverstate
I1123 11:58:58.167062 14481 solver.cpp:231] Iteration 1640, loss = 8.39233e-05
I1123 11:58:58.167086 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:58:58.167091 14481 solver.cpp:545] Iteration 1640, lr = 1e-09
I1123 11:59:07.820412 14481 solver.cpp:231] Iteration 1660, loss = 8.205
I1123 11:59:07.820437 14481 solver.cpp:246]     Train net output #0: loss = 8.20492 (* 1 = 8.20492 loss)
I1123 11:59:07.820444 14481 solver.cpp:545] Iteration 1660, lr = 1e-09
I1123 11:59:17.531633 14481 solver.cpp:231] Iteration 1680, loss = 8.53539e-05
I1123 11:59:17.531657 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:59:17.531664 14481 solver.cpp:545] Iteration 1680, lr = 1e-09
I1123 11:59:27.329799 14481 solver.cpp:231] Iteration 1700, loss = 8.39233e-05
I1123 11:59:27.329823 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:59:27.329828 14481 solver.cpp:545] Iteration 1700, lr = 1e-09
I1123 11:59:37.060890 14481 solver.cpp:231] Iteration 1720, loss = 22.248
I1123 11:59:37.060916 14481 solver.cpp:246]     Train net output #0: loss = 22.2479 (* 1 = 22.2479 loss)
I1123 11:59:37.060922 14481 solver.cpp:545] Iteration 1720, lr = 1e-09
I1123 11:59:46.689782 14481 solver.cpp:231] Iteration 1740, loss = 6.95232
I1123 11:59:46.689806 14481 solver.cpp:246]     Train net output #0: loss = 6.95223 (* 1 = 6.95223 loss)
I1123 11:59:46.689811 14481 solver.cpp:545] Iteration 1740, lr = 1e-09
I1123 11:59:56.296399 14481 solver.cpp:231] Iteration 1760, loss = 8.39233e-05
I1123 11:59:56.296423 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 11:59:56.296428 14481 solver.cpp:545] Iteration 1760, lr = 1e-09
I1123 12:00:05.991225 14481 solver.cpp:231] Iteration 1780, loss = 7.8404
I1123 12:00:05.991246 14481 solver.cpp:246]     Train net output #0: loss = 7.84032 (* 1 = 7.84032 loss)
I1123 12:00:05.991251 14481 solver.cpp:545] Iteration 1780, lr = 1e-09
I1123 12:00:15.703260 14481 solver.cpp:231] Iteration 1800, loss = 4.46057
I1123 12:00:15.703284 14481 solver.cpp:246]     Train net output #0: loss = 4.46049 (* 1 = 4.46049 loss)
I1123 12:00:15.703289 14481 solver.cpp:545] Iteration 1800, lr = 1e-09
I1123 12:00:25.583173 14481 solver.cpp:231] Iteration 1820, loss = 34.8131
I1123 12:00:25.583196 14481 solver.cpp:246]     Train net output #0: loss = 34.813 (* 1 = 34.813 loss)
I1123 12:00:25.583202 14481 solver.cpp:545] Iteration 1820, lr = 1e-09
I1123 12:00:35.308007 14481 solver.cpp:231] Iteration 1840, loss = 13.3121
I1123 12:00:35.308030 14481 solver.cpp:246]     Train net output #0: loss = 13.312 (* 1 = 13.312 loss)
I1123 12:00:35.308037 14481 solver.cpp:545] Iteration 1840, lr = 1e-09
I1123 12:00:45.010787 14481 solver.cpp:231] Iteration 1860, loss = 5.15952
I1123 12:00:45.010812 14481 solver.cpp:246]     Train net output #0: loss = 5.15944 (* 1 = 5.15944 loss)
I1123 12:00:45.010818 14481 solver.cpp:545] Iteration 1860, lr = 1e-09
I1123 12:00:54.712867 14481 solver.cpp:231] Iteration 1880, loss = 21.7764
I1123 12:00:54.712891 14481 solver.cpp:246]     Train net output #0: loss = 21.7764 (* 1 = 21.7764 loss)
I1123 12:00:54.712898 14481 solver.cpp:545] Iteration 1880, lr = 1e-09
I1123 12:01:04.357820 14481 solver.cpp:231] Iteration 1900, loss = 8.01086e-05
I1123 12:01:04.357843 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:01:04.357848 14481 solver.cpp:545] Iteration 1900, lr = 1e-09
I1123 12:01:14.099025 14481 solver.cpp:231] Iteration 1920, loss = 0.0694708
I1123 12:01:14.099061 14481 solver.cpp:246]     Train net output #0: loss = 0.069387 (* 1 = 0.069387 loss)
I1123 12:01:14.099076 14481 solver.cpp:545] Iteration 1920, lr = 1e-09
I1123 12:01:23.893414 14481 solver.cpp:231] Iteration 1940, loss = 11.2843
I1123 12:01:23.893436 14481 solver.cpp:246]     Train net output #0: loss = 11.2842 (* 1 = 11.2842 loss)
I1123 12:01:23.893442 14481 solver.cpp:545] Iteration 1940, lr = 1e-09
I1123 12:01:33.651036 14481 solver.cpp:231] Iteration 1960, loss = 8.01086e-05
I1123 12:01:33.651060 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:01:33.651067 14481 solver.cpp:545] Iteration 1960, lr = 1e-09
I1123 12:01:43.244973 14481 solver.cpp:231] Iteration 1980, loss = 21.1849
I1123 12:01:43.244999 14481 solver.cpp:246]     Train net output #0: loss = 21.1848 (* 1 = 21.1848 loss)
I1123 12:01:43.245004 14481 solver.cpp:545] Iteration 1980, lr = 1e-09
I1123 12:01:52.880872 14481 solver.cpp:231] Iteration 2000, loss = 8.23211
I1123 12:01:52.880894 14481 solver.cpp:246]     Train net output #0: loss = 8.23202 (* 1 = 8.23202 loss)
I1123 12:01:52.880899 14481 solver.cpp:545] Iteration 2000, lr = 1e-09
I1123 12:02:02.543270 14481 solver.cpp:231] Iteration 2020, loss = 2.60144
I1123 12:02:02.543292 14481 solver.cpp:246]     Train net output #0: loss = 2.60136 (* 1 = 2.60136 loss)
I1123 12:02:02.543298 14481 solver.cpp:545] Iteration 2020, lr = 1e-09
I1123 12:02:12.158831 14481 solver.cpp:231] Iteration 2040, loss = 8.39233e-05
I1123 12:02:12.158854 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:02:12.158859 14481 solver.cpp:545] Iteration 2040, lr = 1e-09
I1123 12:02:21.939543 14481 solver.cpp:231] Iteration 2060, loss = 0.143469
I1123 12:02:21.939568 14481 solver.cpp:246]     Train net output #0: loss = 0.143384 (* 1 = 0.143384 loss)
I1123 12:02:21.939573 14481 solver.cpp:545] Iteration 2060, lr = 1e-09
I1123 12:02:31.485958 14481 solver.cpp:231] Iteration 2080, loss = 7.67107
I1123 12:02:31.485982 14481 solver.cpp:246]     Train net output #0: loss = 7.67098 (* 1 = 7.67098 loss)
I1123 12:02:31.485987 14481 solver.cpp:545] Iteration 2080, lr = 1e-09
I1123 12:02:41.141808 14481 solver.cpp:231] Iteration 2100, loss = 0.393448
I1123 12:02:41.141832 14481 solver.cpp:246]     Train net output #0: loss = 0.39336 (* 1 = 0.39336 loss)
I1123 12:02:41.141839 14481 solver.cpp:545] Iteration 2100, lr = 1e-09
I1123 12:02:50.799751 14481 solver.cpp:231] Iteration 2120, loss = 19.474
I1123 12:02:50.799775 14481 solver.cpp:246]     Train net output #0: loss = 19.4739 (* 1 = 19.4739 loss)
I1123 12:02:50.799780 14481 solver.cpp:545] Iteration 2120, lr = 1e-09
I1123 12:03:00.613008 14481 solver.cpp:231] Iteration 2140, loss = 8.2016e-05
I1123 12:03:00.613031 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:03:00.613036 14481 solver.cpp:545] Iteration 2140, lr = 1e-09
I1123 12:03:10.262032 14481 solver.cpp:231] Iteration 2160, loss = 8.39233e-05
I1123 12:03:10.262056 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:03:10.262061 14481 solver.cpp:545] Iteration 2160, lr = 1e-09
I1123 12:03:19.915917 14481 solver.cpp:231] Iteration 2180, loss = 62.8602
I1123 12:03:19.915942 14481 solver.cpp:246]     Train net output #0: loss = 62.8601 (* 1 = 62.8601 loss)
I1123 12:03:19.915947 14481 solver.cpp:545] Iteration 2180, lr = 1e-09
I1123 12:03:29.622016 14481 solver.cpp:231] Iteration 2200, loss = 8.10623e-05
I1123 12:03:29.622040 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:03:29.622045 14481 solver.cpp:545] Iteration 2200, lr = 1e-09
I1123 12:03:39.267753 14481 solver.cpp:231] Iteration 2220, loss = 8.39233e-05
I1123 12:03:39.267777 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:03:39.267783 14481 solver.cpp:545] Iteration 2220, lr = 1e-09
I1123 12:03:48.936336 14481 solver.cpp:231] Iteration 2240, loss = 29.3739
I1123 12:03:48.936372 14481 solver.cpp:246]     Train net output #0: loss = 29.3739 (* 1 = 29.3739 loss)
I1123 12:03:48.936378 14481 solver.cpp:545] Iteration 2240, lr = 1e-09
I1123 12:03:58.546308 14481 solver.cpp:231] Iteration 2260, loss = 8.39233e-05
I1123 12:03:58.546331 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:03:58.546336 14481 solver.cpp:545] Iteration 2260, lr = 1e-09
I1123 12:04:08.312165 14481 solver.cpp:231] Iteration 2280, loss = 2.65081
I1123 12:04:08.312187 14481 solver.cpp:246]     Train net output #0: loss = 2.65073 (* 1 = 2.65073 loss)
I1123 12:04:08.312192 14481 solver.cpp:545] Iteration 2280, lr = 1e-09
I1123 12:04:18.035146 14481 solver.cpp:231] Iteration 2300, loss = 53.7124
I1123 12:04:18.035171 14481 solver.cpp:246]     Train net output #0: loss = 53.7123 (* 1 = 53.7123 loss)
I1123 12:04:18.035176 14481 solver.cpp:545] Iteration 2300, lr = 1e-09
I1123 12:04:27.790884 14481 solver.cpp:231] Iteration 2320, loss = 4.86459
I1123 12:04:27.790906 14481 solver.cpp:246]     Train net output #0: loss = 4.86452 (* 1 = 4.86452 loss)
I1123 12:04:27.790912 14481 solver.cpp:545] Iteration 2320, lr = 1e-09
I1123 12:04:37.585021 14481 solver.cpp:231] Iteration 2340, loss = 6.86646e-05
I1123 12:04:37.585045 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:04:37.585050 14481 solver.cpp:545] Iteration 2340, lr = 1e-09
I1123 12:04:47.279156 14481 solver.cpp:231] Iteration 2360, loss = 6.48499e-05
I1123 12:04:47.279180 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:04:47.279184 14481 solver.cpp:545] Iteration 2360, lr = 1e-09
I1123 12:04:56.969101 14481 solver.cpp:231] Iteration 2380, loss = 6.48499e-05
I1123 12:04:56.969125 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:04:56.969130 14481 solver.cpp:545] Iteration 2380, lr = 1e-09
I1123 12:05:06.581002 14481 solver.cpp:231] Iteration 2400, loss = 1.06416
I1123 12:05:06.581025 14481 solver.cpp:246]     Train net output #0: loss = 1.06409 (* 1 = 1.06409 loss)
I1123 12:05:06.581030 14481 solver.cpp:545] Iteration 2400, lr = 1e-09
I1123 12:05:16.309967 14481 solver.cpp:231] Iteration 2420, loss = 3.07788
I1123 12:05:16.309991 14481 solver.cpp:246]     Train net output #0: loss = 3.07781 (* 1 = 3.07781 loss)
I1123 12:05:16.309996 14481 solver.cpp:545] Iteration 2420, lr = 1e-09
I1123 12:05:22.447928 14481 solver.cpp:415] Snapshotting to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_2433.caffemodel
I1123 12:05:22.865867 14481 solver.cpp:423] Snapshotting solver state to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_2433.solverstate
I1123 12:05:26.843729 14481 solver.cpp:231] Iteration 2440, loss = 7.62939e-05
I1123 12:05:26.843751 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:05:26.843757 14481 solver.cpp:545] Iteration 2440, lr = 1e-09
I1123 12:05:36.485000 14481 solver.cpp:231] Iteration 2460, loss = 5.73825
I1123 12:05:36.485024 14481 solver.cpp:246]     Train net output #0: loss = 5.73818 (* 1 = 5.73818 loss)
I1123 12:05:36.485029 14481 solver.cpp:545] Iteration 2460, lr = 1e-09
I1123 12:05:46.164191 14481 solver.cpp:231] Iteration 2480, loss = 20.3853
I1123 12:05:46.164216 14481 solver.cpp:246]     Train net output #0: loss = 20.3852 (* 1 = 20.3852 loss)
I1123 12:05:46.164222 14481 solver.cpp:545] Iteration 2480, lr = 1e-09
I1123 12:05:55.891070 14481 solver.cpp:231] Iteration 2500, loss = 7.82013e-05
I1123 12:05:55.891093 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:05:55.891099 14481 solver.cpp:545] Iteration 2500, lr = 1e-09
I1123 12:06:05.649205 14481 solver.cpp:231] Iteration 2520, loss = 7.62939e-05
I1123 12:06:05.649227 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:06:05.649232 14481 solver.cpp:545] Iteration 2520, lr = 1e-09
I1123 12:06:15.401196 14481 solver.cpp:231] Iteration 2540, loss = 2.82296
I1123 12:06:15.401221 14481 solver.cpp:246]     Train net output #0: loss = 2.82289 (* 1 = 2.82289 loss)
I1123 12:06:15.401226 14481 solver.cpp:545] Iteration 2540, lr = 1e-09
I1123 12:06:25.006794 14481 solver.cpp:231] Iteration 2560, loss = 6.26586
I1123 12:06:25.006819 14481 solver.cpp:246]     Train net output #0: loss = 6.26578 (* 1 = 6.26578 loss)
I1123 12:06:25.006824 14481 solver.cpp:545] Iteration 2560, lr = 1e-09
I1123 12:06:34.718715 14481 solver.cpp:231] Iteration 2580, loss = 8.01086e-05
I1123 12:06:34.718740 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:06:34.718745 14481 solver.cpp:545] Iteration 2580, lr = 1e-09
I1123 12:06:44.393142 14481 solver.cpp:231] Iteration 2600, loss = 11.2893
I1123 12:06:44.393167 14481 solver.cpp:246]     Train net output #0: loss = 11.2892 (* 1 = 11.2892 loss)
I1123 12:06:44.393172 14481 solver.cpp:545] Iteration 2600, lr = 1e-09
I1123 12:06:54.075040 14481 solver.cpp:231] Iteration 2620, loss = 20.9319
I1123 12:06:54.075065 14481 solver.cpp:246]     Train net output #0: loss = 20.9318 (* 1 = 20.9318 loss)
I1123 12:06:54.075070 14481 solver.cpp:545] Iteration 2620, lr = 1e-09
I1123 12:07:03.813715 14481 solver.cpp:231] Iteration 2640, loss = 7.86591
I1123 12:07:03.813740 14481 solver.cpp:246]     Train net output #0: loss = 7.86583 (* 1 = 7.86583 loss)
I1123 12:07:03.813745 14481 solver.cpp:545] Iteration 2640, lr = 1e-09
I1123 12:07:13.588273 14481 solver.cpp:231] Iteration 2660, loss = 34.6908
I1123 12:07:13.588297 14481 solver.cpp:246]     Train net output #0: loss = 34.6907 (* 1 = 34.6907 loss)
I1123 12:07:13.588304 14481 solver.cpp:545] Iteration 2660, lr = 1e-09
I1123 12:07:23.228899 14481 solver.cpp:231] Iteration 2680, loss = 7.43866e-05
I1123 12:07:23.228922 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:07:23.228927 14481 solver.cpp:545] Iteration 2680, lr = 1e-09
I1123 12:07:32.954023 14481 solver.cpp:231] Iteration 2700, loss = 0.148016
I1123 12:07:32.954047 14481 solver.cpp:246]     Train net output #0: loss = 0.147951 (* 1 = 0.147951 loss)
I1123 12:07:32.954052 14481 solver.cpp:545] Iteration 2700, lr = 1e-09
I1123 12:07:42.641579 14481 solver.cpp:231] Iteration 2720, loss = 11.498
I1123 12:07:42.641603 14481 solver.cpp:246]     Train net output #0: loss = 11.4979 (* 1 = 11.4979 loss)
I1123 12:07:42.641608 14481 solver.cpp:545] Iteration 2720, lr = 1e-09
I1123 12:07:52.385632 14481 solver.cpp:231] Iteration 2740, loss = 25.6999
I1123 12:07:52.385656 14481 solver.cpp:246]     Train net output #0: loss = 25.6998 (* 1 = 25.6998 loss)
I1123 12:07:52.385661 14481 solver.cpp:545] Iteration 2740, lr = 1e-09
I1123 12:08:02.102051 14481 solver.cpp:231] Iteration 2760, loss = 1.40957
I1123 12:08:02.102074 14481 solver.cpp:246]     Train net output #0: loss = 1.40951 (* 1 = 1.40951 loss)
I1123 12:08:02.102079 14481 solver.cpp:545] Iteration 2760, lr = 1e-09
I1123 12:08:11.805817 14481 solver.cpp:231] Iteration 2780, loss = 47.3344
I1123 12:08:11.805841 14481 solver.cpp:246]     Train net output #0: loss = 47.3344 (* 1 = 47.3344 loss)
I1123 12:08:11.805846 14481 solver.cpp:545] Iteration 2780, lr = 1e-09
I1123 12:08:21.479068 14481 solver.cpp:231] Iteration 2800, loss = 5.91278e-05
I1123 12:08:21.479090 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:08:21.479095 14481 solver.cpp:545] Iteration 2800, lr = 1e-09
I1123 12:08:31.243860 14481 solver.cpp:231] Iteration 2820, loss = 6.10352e-05
I1123 12:08:31.243883 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:08:31.243890 14481 solver.cpp:545] Iteration 2820, lr = 1e-09
I1123 12:08:40.852360 14481 solver.cpp:231] Iteration 2840, loss = 5.67436e-05
I1123 12:08:40.852385 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:08:40.852390 14481 solver.cpp:545] Iteration 2840, lr = 1e-09
I1123 12:08:50.522969 14481 solver.cpp:231] Iteration 2860, loss = 5.72205e-05
I1123 12:08:50.522994 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:08:50.522999 14481 solver.cpp:545] Iteration 2860, lr = 1e-09
I1123 12:09:00.170300 14481 solver.cpp:231] Iteration 2880, loss = 24.1605
I1123 12:09:00.170322 14481 solver.cpp:246]     Train net output #0: loss = 24.1604 (* 1 = 24.1604 loss)
I1123 12:09:00.170328 14481 solver.cpp:545] Iteration 2880, lr = 1e-09
I1123 12:09:09.796458 14481 solver.cpp:231] Iteration 2900, loss = 0.730238
I1123 12:09:09.796481 14481 solver.cpp:246]     Train net output #0: loss = 0.730177 (* 1 = 0.730177 loss)
I1123 12:09:09.796486 14481 solver.cpp:545] Iteration 2900, lr = 1e-09
I1123 12:09:19.425786 14481 solver.cpp:231] Iteration 2920, loss = 6.10352e-05
I1123 12:09:19.425812 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:09:19.425817 14481 solver.cpp:545] Iteration 2920, lr = 1e-09
I1123 12:09:29.174171 14481 solver.cpp:231] Iteration 2940, loss = 25.1686
I1123 12:09:29.174196 14481 solver.cpp:246]     Train net output #0: loss = 25.1686 (* 1 = 25.1686 loss)
I1123 12:09:29.174201 14481 solver.cpp:545] Iteration 2940, lr = 1e-09
I1123 12:09:38.835813 14481 solver.cpp:231] Iteration 2960, loss = 6.10767
I1123 12:09:38.835837 14481 solver.cpp:246]     Train net output #0: loss = 6.10761 (* 1 = 6.10761 loss)
I1123 12:09:38.835842 14481 solver.cpp:545] Iteration 2960, lr = 1e-09
I1123 12:09:48.429536 14481 solver.cpp:231] Iteration 2980, loss = 10.3113
I1123 12:09:48.429559 14481 solver.cpp:246]     Train net output #0: loss = 10.3112 (* 1 = 10.3112 loss)
I1123 12:09:48.429564 14481 solver.cpp:545] Iteration 2980, lr = 1e-09
I1123 12:09:58.161293 14481 solver.cpp:231] Iteration 3000, loss = 6.59875
I1123 12:09:58.161315 14481 solver.cpp:246]     Train net output #0: loss = 6.59869 (* 1 = 6.59869 loss)
I1123 12:09:58.161321 14481 solver.cpp:545] Iteration 3000, lr = 1e-09
I1123 12:10:07.850735 14481 solver.cpp:231] Iteration 3020, loss = 18.3567
I1123 12:10:07.850760 14481 solver.cpp:246]     Train net output #0: loss = 18.3567 (* 1 = 18.3567 loss)
I1123 12:10:07.850766 14481 solver.cpp:545] Iteration 3020, lr = 1e-09
I1123 12:10:17.480768 14481 solver.cpp:231] Iteration 3040, loss = 15.3173
I1123 12:10:17.480792 14481 solver.cpp:246]     Train net output #0: loss = 15.3173 (* 1 = 15.3173 loss)
I1123 12:10:17.480798 14481 solver.cpp:545] Iteration 3040, lr = 1e-09
I1123 12:10:27.089996 14481 solver.cpp:231] Iteration 3060, loss = 5.34058e-05
I1123 12:10:27.090020 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:10:27.090026 14481 solver.cpp:545] Iteration 3060, lr = 1e-09
I1123 12:10:36.807221 14481 solver.cpp:231] Iteration 3080, loss = 0.596626
I1123 12:10:36.807245 14481 solver.cpp:246]     Train net output #0: loss = 0.596575 (* 1 = 0.596575 loss)
I1123 12:10:36.807251 14481 solver.cpp:545] Iteration 3080, lr = 1e-09
I1123 12:10:46.571180 14481 solver.cpp:231] Iteration 3100, loss = 20.3593
I1123 12:10:46.571205 14481 solver.cpp:246]     Train net output #0: loss = 20.3592 (* 1 = 20.3592 loss)
I1123 12:10:46.571210 14481 solver.cpp:545] Iteration 3100, lr = 1e-09
I1123 12:10:56.335628 14481 solver.cpp:231] Iteration 3120, loss = 3.40696
I1123 12:10:56.335652 14481 solver.cpp:246]     Train net output #0: loss = 3.40691 (* 1 = 3.40691 loss)
I1123 12:10:56.335659 14481 solver.cpp:545] Iteration 3120, lr = 1e-09
I1123 12:11:06.187134 14481 solver.cpp:231] Iteration 3140, loss = 12.6001
I1123 12:11:06.187160 14481 solver.cpp:246]     Train net output #0: loss = 12.6001 (* 1 = 12.6001 loss)
I1123 12:11:06.187165 14481 solver.cpp:545] Iteration 3140, lr = 1e-09
I1123 12:11:15.842000 14481 solver.cpp:231] Iteration 3160, loss = 67.0184
I1123 12:11:15.842025 14481 solver.cpp:246]     Train net output #0: loss = 67.0183 (* 1 = 67.0183 loss)
I1123 12:11:15.842031 14481 solver.cpp:545] Iteration 3160, lr = 1e-09
I1123 12:11:25.516207 14481 solver.cpp:231] Iteration 3180, loss = 1.12794
I1123 12:11:25.516230 14481 solver.cpp:246]     Train net output #0: loss = 1.1279 (* 1 = 1.1279 loss)
I1123 12:11:25.516237 14481 solver.cpp:545] Iteration 3180, lr = 1e-09
I1123 12:11:35.172951 14481 solver.cpp:231] Iteration 3200, loss = 4.95462
I1123 12:11:35.172974 14481 solver.cpp:246]     Train net output #0: loss = 4.95457 (* 1 = 4.95457 loss)
I1123 12:11:35.172979 14481 solver.cpp:545] Iteration 3200, lr = 1e-09
I1123 12:11:44.824435 14481 solver.cpp:231] Iteration 3220, loss = 4.55976e-05
I1123 12:11:44.824457 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:11:44.824462 14481 solver.cpp:545] Iteration 3220, lr = 1e-09
I1123 12:11:54.516573 14481 solver.cpp:231] Iteration 3240, loss = 6.98928
I1123 12:11:54.516597 14481 solver.cpp:246]     Train net output #0: loss = 6.98924 (* 1 = 6.98924 loss)
I1123 12:11:54.516602 14481 solver.cpp:545] Iteration 3240, lr = 1e-09
I1123 12:11:56.306540 14481 solver.cpp:415] Snapshotting to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_3244.caffemodel
I1123 12:11:56.724447 14481 solver.cpp:423] Snapshotting solver state to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_3244.solverstate
I1123 12:12:05.087915 14481 solver.cpp:231] Iteration 3260, loss = 27.1752
I1123 12:12:05.087939 14481 solver.cpp:246]     Train net output #0: loss = 27.1751 (* 1 = 27.1751 loss)
I1123 12:12:05.087945 14481 solver.cpp:545] Iteration 3260, lr = 1e-10
I1123 12:12:14.710721 14481 solver.cpp:231] Iteration 3280, loss = 82.7986
I1123 12:12:14.710744 14481 solver.cpp:246]     Train net output #0: loss = 82.7986 (* 1 = 82.7986 loss)
I1123 12:12:14.710750 14481 solver.cpp:545] Iteration 3280, lr = 1e-10
I1123 12:12:24.411317 14481 solver.cpp:231] Iteration 3300, loss = 9.7193
I1123 12:12:24.411342 14481 solver.cpp:246]     Train net output #0: loss = 9.71926 (* 1 = 9.71926 loss)
I1123 12:12:24.411347 14481 solver.cpp:545] Iteration 3300, lr = 1e-10
I1123 12:12:34.199525 14481 solver.cpp:231] Iteration 3320, loss = 33.0891
I1123 12:12:34.199559 14481 solver.cpp:246]     Train net output #0: loss = 33.089 (* 1 = 33.089 loss)
I1123 12:12:34.199565 14481 solver.cpp:545] Iteration 3320, lr = 1e-10
I1123 12:12:43.904455 14481 solver.cpp:231] Iteration 3340, loss = 61.98
I1123 12:12:43.904479 14481 solver.cpp:246]     Train net output #0: loss = 61.98 (* 1 = 61.98 loss)
I1123 12:12:43.904484 14481 solver.cpp:545] Iteration 3340, lr = 1e-10
I1123 12:12:53.534641 14481 solver.cpp:231] Iteration 3360, loss = 12.6546
I1123 12:12:53.534677 14481 solver.cpp:246]     Train net output #0: loss = 12.6546 (* 1 = 12.6546 loss)
I1123 12:12:53.534682 14481 solver.cpp:545] Iteration 3360, lr = 1e-10
I1123 12:13:03.184352 14481 solver.cpp:231] Iteration 3380, loss = 3.49673
I1123 12:13:03.184393 14481 solver.cpp:246]     Train net output #0: loss = 3.49669 (* 1 = 3.49669 loss)
I1123 12:13:03.184399 14481 solver.cpp:545] Iteration 3380, lr = 1e-10
I1123 12:13:12.868288 14481 solver.cpp:231] Iteration 3400, loss = 12.636
I1123 12:13:12.868314 14481 solver.cpp:246]     Train net output #0: loss = 12.636 (* 1 = 12.636 loss)
I1123 12:13:12.868319 14481 solver.cpp:545] Iteration 3400, lr = 1e-10
I1123 12:13:22.491180 14481 solver.cpp:231] Iteration 3420, loss = 2.52797
I1123 12:13:22.491204 14481 solver.cpp:246]     Train net output #0: loss = 2.52793 (* 1 = 2.52793 loss)
I1123 12:13:22.491209 14481 solver.cpp:545] Iteration 3420, lr = 1e-10
I1123 12:13:32.292492 14481 solver.cpp:231] Iteration 3440, loss = 3.12975
I1123 12:13:32.292515 14481 solver.cpp:246]     Train net output #0: loss = 3.12971 (* 1 = 3.12971 loss)
I1123 12:13:32.292521 14481 solver.cpp:545] Iteration 3440, lr = 1e-10
I1123 12:13:42.100163 14481 solver.cpp:231] Iteration 3460, loss = 3.33786e-05
I1123 12:13:42.100188 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:13:42.100193 14481 solver.cpp:545] Iteration 3460, lr = 1e-10
I1123 12:13:51.761332 14481 solver.cpp:231] Iteration 3480, loss = 3.43323e-05
I1123 12:13:51.761356 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:13:51.761363 14481 solver.cpp:545] Iteration 3480, lr = 1e-10
I1123 12:14:01.452358 14481 solver.cpp:231] Iteration 3500, loss = 3.62396e-05
I1123 12:14:01.452383 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:14:01.452388 14481 solver.cpp:545] Iteration 3500, lr = 1e-10
I1123 12:14:11.240905 14481 solver.cpp:231] Iteration 3520, loss = 3.05176e-05
I1123 12:14:11.240928 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:14:11.240933 14481 solver.cpp:545] Iteration 3520, lr = 1e-10
I1123 12:14:20.946295 14481 solver.cpp:231] Iteration 3540, loss = 2.17288
I1123 12:14:20.946319 14481 solver.cpp:246]     Train net output #0: loss = 2.17285 (* 1 = 2.17285 loss)
I1123 12:14:20.946326 14481 solver.cpp:545] Iteration 3540, lr = 1e-10
I1123 12:14:30.605886 14481 solver.cpp:231] Iteration 3560, loss = 3.43323e-05
I1123 12:14:30.605921 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:14:30.605927 14481 solver.cpp:545] Iteration 3560, lr = 1e-10
I1123 12:14:40.219506 14481 solver.cpp:231] Iteration 3580, loss = 3.43323e-05
I1123 12:14:40.219528 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:14:40.219534 14481 solver.cpp:545] Iteration 3580, lr = 1e-10
I1123 12:14:49.870666 14481 solver.cpp:231] Iteration 3600, loss = 4.74131
I1123 12:14:49.870689 14481 solver.cpp:246]     Train net output #0: loss = 4.74127 (* 1 = 4.74127 loss)
I1123 12:14:49.870694 14481 solver.cpp:545] Iteration 3600, lr = 1e-10
I1123 12:14:59.612442 14481 solver.cpp:231] Iteration 3620, loss = 25.0367
I1123 12:14:59.612469 14481 solver.cpp:246]     Train net output #0: loss = 25.0367 (* 1 = 25.0367 loss)
I1123 12:14:59.612476 14481 solver.cpp:545] Iteration 3620, lr = 1e-10
I1123 12:15:09.331954 14481 solver.cpp:231] Iteration 3640, loss = 15.7662
I1123 12:15:09.331979 14481 solver.cpp:246]     Train net output #0: loss = 15.7662 (* 1 = 15.7662 loss)
I1123 12:15:09.331984 14481 solver.cpp:545] Iteration 3640, lr = 1e-10
I1123 12:15:19.008945 14481 solver.cpp:231] Iteration 3660, loss = 7.194
I1123 12:15:19.008968 14481 solver.cpp:246]     Train net output #0: loss = 7.19397 (* 1 = 7.19397 loss)
I1123 12:15:19.008975 14481 solver.cpp:545] Iteration 3660, lr = 1e-10
I1123 12:15:28.700467 14481 solver.cpp:231] Iteration 3680, loss = 11.1675
I1123 12:15:28.700502 14481 solver.cpp:246]     Train net output #0: loss = 11.1675 (* 1 = 11.1675 loss)
I1123 12:15:28.700510 14481 solver.cpp:545] Iteration 3680, lr = 1e-10
I1123 12:15:38.302702 14481 solver.cpp:231] Iteration 3700, loss = 4.43012
I1123 12:15:38.302727 14481 solver.cpp:246]     Train net output #0: loss = 4.43009 (* 1 = 4.43009 loss)
I1123 12:15:38.302733 14481 solver.cpp:545] Iteration 3700, lr = 1e-10
I1123 12:15:47.931911 14481 solver.cpp:231] Iteration 3720, loss = 3.24249e-05
I1123 12:15:47.931934 14481 solver.cpp:246]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1123 12:15:47.931941 14481 solver.cpp:545] Iteration 3720, lr = 1e-10
I1123 12:15:57.596949 14481 solver.cpp:231] Iteration 3740, loss = 12.4501
I1123 12:15:57.596973 14481 solver.cpp:246]     Train net output #0: loss = 12.4501 (* 1 = 12.4501 loss)
I1123 12:15:57.596979 14481 solver.cpp:545] Iteration 3740, lr = 1e-10
I1123 12:16:07.467427 14481 solver.cpp:231] Iteration 3760, loss = 26.9149
I1123 12:16:07.467453 14481 solver.cpp:246]     Train net output #0: loss = 26.9148 (* 1 = 26.9148 loss)
I1123 12:16:07.467459 14481 solver.cpp:545] Iteration 3760, lr = 1e-10
I1123 12:16:17.137128 14481 solver.cpp:231] Iteration 3780, loss = 65.367
I1123 12:16:17.137153 14481 solver.cpp:246]     Train net output #0: loss = 65.3669 (* 1 = 65.3669 loss)
I1123 12:16:17.137159 14481 solver.cpp:545] Iteration 3780, lr = 1e-10
I1123 12:16:26.769233 14481 solver.cpp:231] Iteration 3800, loss = 2.88516
I1123 12:16:26.769258 14481 solver.cpp:246]     Train net output #0: loss = 2.88513 (* 1 = 2.88513 loss)
I1123 12:16:26.769263 14481 solver.cpp:545] Iteration 3800, lr = 1e-10
I1123 12:16:36.514993 14481 solver.cpp:231] Iteration 3820, loss = 0.322514
I1123 12:16:36.515017 14481 solver.cpp:246]     Train net output #0: loss = 0.322486 (* 1 = 0.322486 loss)
I1123 12:16:36.515022 14481 solver.cpp:545] Iteration 3820, lr = 1e-10
I1123 12:16:46.192518 14481 solver.cpp:231] Iteration 3840, loss = 6.71832
I1123 12:16:46.192541 14481 solver.cpp:246]     Train net output #0: loss = 6.7183 (* 1 = 6.7183 loss)
I1123 12:16:46.192548 14481 solver.cpp:545] Iteration 3840, lr = 1e-10
I1123 12:16:55.913115 14481 solver.cpp:231] Iteration 3860, loss = 5.77051
I1123 12:16:55.913138 14481 solver.cpp:246]     Train net output #0: loss = 5.77049 (* 1 = 5.77049 loss)
I1123 12:16:55.913143 14481 solver.cpp:545] Iteration 3860, lr = 1e-10
I1123 12:17:05.579146 14481 solver.cpp:231] Iteration 3880, loss = 0.315407
I1123 12:17:05.579171 14481 solver.cpp:246]     Train net output #0: loss = 0.31538 (* 1 = 0.31538 loss)
I1123 12:17:05.579176 14481 solver.cpp:545] Iteration 3880, lr = 1e-10
I1123 12:17:15.331794 14481 solver.cpp:231] Iteration 3900, loss = 10.2956
I1123 12:17:15.331816 14481 solver.cpp:246]     Train net output #0: loss = 10.2956 (* 1 = 10.2956 loss)
I1123 12:17:15.331822 14481 solver.cpp:545] Iteration 3900, lr = 1e-10
I1123 12:17:24.999704 14481 solver.cpp:231] Iteration 3920, loss = 34.2623
I1123 12:17:24.999730 14481 solver.cpp:246]     Train net output #0: loss = 34.2623 (* 1 = 34.2623 loss)
I1123 12:17:24.999737 14481 solver.cpp:545] Iteration 3920, lr = 1e-10
I1123 12:17:34.880570 14481 solver.cpp:231] Iteration 3940, loss = 4.2488
I1123 12:17:34.880592 14481 solver.cpp:246]     Train net output #0: loss = 4.24876 (* 1 = 4.24876 loss)
I1123 12:17:34.880599 14481 solver.cpp:545] Iteration 3940, lr = 1e-10
I1123 12:17:44.643332 14481 solver.cpp:231] Iteration 3960, loss = 42.9632
I1123 12:17:44.643355 14481 solver.cpp:246]     Train net output #0: loss = 42.9632 (* 1 = 42.9632 loss)
I1123 12:17:44.643360 14481 solver.cpp:545] Iteration 3960, lr = 1e-10
I1123 12:17:54.245262 14481 solver.cpp:231] Iteration 3980, loss = 12.39
I1123 12:17:54.245286 14481 solver.cpp:246]     Train net output #0: loss = 12.39 (* 1 = 12.39 loss)
I1123 12:17:54.245292 14481 solver.cpp:545] Iteration 3980, lr = 1e-10
I1123 12:18:03.940377 14481 solver.cpp:231] Iteration 4000, loss = 1.31547
I1123 12:18:03.940410 14481 solver.cpp:246]     Train net output #0: loss = 1.31543 (* 1 = 1.31543 loss)
I1123 12:18:03.940417 14481 solver.cpp:545] Iteration 4000, lr = 1e-10
I1123 12:18:13.527410 14481 solver.cpp:231] Iteration 4020, loss = 1.00688
I1123 12:18:13.527432 14481 solver.cpp:246]     Train net output #0: loss = 1.00684 (* 1 = 1.00684 loss)
I1123 12:18:13.527437 14481 solver.cpp:545] Iteration 4020, lr = 1e-10
I1123 12:18:23.259734 14481 solver.cpp:231] Iteration 4040, loss = 10.609
I1123 12:18:23.259780 14481 solver.cpp:246]     Train net output #0: loss = 10.609 (* 1 = 10.609 loss)
I1123 12:18:23.259796 14481 solver.cpp:545] Iteration 4040, lr = 1e-10
I1123 12:18:30.408318 14481 solver.cpp:415] Snapshotting to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_4055.caffemodel
I1123 12:18:30.827280 14481 solver.cpp:423] Snapshotting solver state to /local-scratch/xla193/cluster_video_/output/UCF-101/snapshots_lstm_RGB/1_-8_iter_4055.solverstate
I1123 12:18:31.074821 14481 solver.cpp:312] Optimization Done.
I1123 12:18:31.074833 14481 caffe.cpp:165] Optimization Done.
Done.
